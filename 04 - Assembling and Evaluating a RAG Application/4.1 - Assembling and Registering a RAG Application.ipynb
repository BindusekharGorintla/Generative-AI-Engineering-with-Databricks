{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71e0c5de-caf1-4df0-92f1-39cd3c638782",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f50f6c4-0045-482c-8da1-3249df99fc8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Assembling and Registering a RAG Application\n",
    "\n",
    "In the previous demo, we created a Vector Search Index. To build a complete RAG application, it is time to connect all the components that you have learned so far and evaluate the performance of the RAG.\n",
    "\n",
    "After evaluating the performance of the RAG pipeline, we will create and deploy a new Model Serving Endpoint to perform RAG.\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "*By the end of this demo, you will be able to:*\n",
    "\n",
    "- Describe embeddings, vector databases, and search/retrieval as key components of implementing performant RAG applications.\n",
    "- Assemble a RAG pipeline by combining various components.\n",
    "- Build a RAG evaluation pipeline with MLflow evaluation functions.\n",
    "- Register a RAG pipeline to the Model Registry.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8f6e6a9-c06a-4e39-b124-59be87bb5c26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "2. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "   - Click **More** in the drop-down.\n",
    "   \n",
    "   - In the **Attach to an existing compute resource** window, use the first drop-down to select your unique cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "2. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "3. Wait a few minutes for the cluster to start.\n",
    "\n",
    "4. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08557fba-8c36-4206-a3f0-276e107b218b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**\n",
    "\n",
    "\n",
    "\n",
    "**\uD83D\uDEA8 Important: This demonstration relies on the resources established in the previous one. Please ensure you have completed the prior demonstration before starting this one.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "035039e9-9ff3-4aaf-a3d9-515b5f77be1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Classroom Setup\n",
    "\n",
    "Install required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4f333fb-10d1-4340-afba-b6f74b2d14ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqq databricks-sdk databricks-vectorsearch 'mlflow-skinny[databricks]==3.4.0' langchain==0.3.26 databricks-langchain==0.8.0 PyPDF2==3.0.0 flashrank\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "999b6a8f-c50a-4dda-9722-634c9d8c51b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Before starting the demo, run the provided classroom setup script. This script will define configuration variables necessary for the demo. Execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94ec631d-6988-479a-b575-d2037ff8b680",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83d52ba9-938a-4df7-89de-c17daaa3fe9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Other Conventions:**\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6648c842-09fd-4d6e-a1b1-52ba353bf6df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"Dataset Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "243a5384-7c19-4628-a61e-1410a673b5b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Demo Overview\n",
    "\n",
    "As seen in the diagram below, in this demo we will focus on the inference section (highlighted in green). The main focus of the previous demos was  Step 1 - Data preparation and vector storage. Now, it is time to put all components together to create a RAG application. \n",
    "\n",
    "The flow will be the following:\n",
    "\n",
    "- A user asks a question\n",
    "- The question is sent to our serverless Chatbot RAG endpoint\n",
    "- The endpoint compute the embeddings and searches for docs similar to the question, leveraging the Vector Search Index\n",
    "- The endpoint creates a prompt enriched with the doc\n",
    "- The prompt is sent to the Foundation Model Serving Endpoint\n",
    "- We display the output to our users!\n",
    "\n",
    "\n",
    "<!-- <img src=\"https://files.training.databricks.com/images/genai/genai-as-01-llm-rag-self-managed-flow-2.png\" width=\"100%\"> -->\n",
    "\n",
    "<!--  -->\n",
    "\n",
    "![genai-as-01-llm-rag-self-managed-flow-2](../Includes/images/genai-as-01-llm-rag-self-managed-flow-2.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c734725-d994-4eab-aa28-f2ccc739e048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup the RAG Components\n",
    "\n",
    "In this section, we will first define the components that we created before. Next, we will set up the retriever component for the application. Then, we will combine all the components together. In the final step, we will register the developed application as a model in the Model Registry with Unity Catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d7e4bbb-ea66-43d7-a762-3eb24f6a43fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setup the Retriever\n",
    "\n",
    "We will setup the Vector Search endpoint that we created in the previous demos as retriever. The retriever will return 2 relevant documents based on the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a2085db-5ce5-4760-92ef-4c2607c32cae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# components we created before\n",
    "# assign vs search endpoint by username\n",
    "vs_endpoint_prefix = \"vs_endpoint_\"\n",
    "\n",
    "vs_endpoint_name = vs_endpoint_prefix + str(get_fixed_integer(DA.unique_name(\"_\")))\n",
    "print(f\"Assigned Vector Search endpoint name: {vs_endpoint_name}.\")\n",
    "\n",
    "vs_index_fullname = f\"{DA.catalog_name}.{DA.schema_name}.pdf_text_self_managed_vs_index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6febf6c1-c1c5-4392-954d-2e1aba497b91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks_langchain import DatabricksEmbeddings\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.documents import Document\n",
    "from flashrank import Ranker, RerankRequest\n",
    "\n",
    "def get_retriever(cache_dir=\"/tmp\"):\n",
    "\n",
    "    def retrieve(query, k: int=10):\n",
    "        if isinstance(query, dict):\n",
    "            query = next(iter(query.values()))\n",
    "\n",
    "        # get the vector search index\n",
    "        vsc = VectorSearchClient(disable_notice=True)\n",
    "        vs_index = vsc.get_index(endpoint_name=vs_endpoint_name, index_name=vs_index_fullname)\n",
    "        \n",
    "        # get the query vector\n",
    "        embeddings = DatabricksEmbeddings(endpoint=\"databricks-gte-large-en\")\n",
    "        query_vector = embeddings.embed_query(query)\n",
    "        \n",
    "        # get similar k documents\n",
    "        return query, vs_index.similarity_search(\n",
    "            query_vector=query_vector,\n",
    "            columns=[\"pdf_name\", \"content\"],\n",
    "            num_results=k)\n",
    "\n",
    "    def rerank(query, retrieved, cache_dir, k: int=2):\n",
    "        # format result to align with reranker lib format \n",
    "        passages = []\n",
    "        for doc in retrieved.get(\"result\", {}).get(\"data_array\", []):\n",
    "            new_doc = {\"file\": doc[0], \"text\": doc[1]}\n",
    "            passages.append(new_doc)       \n",
    "        # Load the flashrank ranker\n",
    "        ranker = Ranker(model_name=\"rank-T5-flan\", cache_dir=cache_dir)\n",
    "\n",
    "        # rerank the retrieved documents\n",
    "        rerankrequest = RerankRequest(query=query, passages=passages)\n",
    "        results = ranker.rerank(rerankrequest)[:k]\n",
    "\n",
    "        # format the results of rerank to be ready for prompt\n",
    "        return [Document(page_content=r.get(\"text\"), metadata={\"source\": r.get(\"file\")}) for r in results]\n",
    "\n",
    "    # the retriever is a runnable sequence of retrieving and reranking.\n",
    "    return RunnableLambda(retrieve) | RunnableLambda(lambda x: rerank(x[0], x[1], cache_dir))\n",
    "\n",
    "# test our retriever\n",
    "question = {\"input\": \"What is Inductive Learning?\"}\n",
    "vectorstore = get_retriever(cache_dir = f\"{DA.paths.working_dir}/opt\")\n",
    "similar_documents = vectorstore.invoke(question)\n",
    "print(f\"Relevant documents: {similar_documents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8c8e5ff-40a1-4638-b29e-62d282ed3378",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setup the Foundation Model\n",
    "\n",
    "Our chatbot will be using `llama3.3` foundation model to provide answer. \n",
    "\n",
    "While the model is available using the built-in [Foundation endpoint](/ml/endpoints), we can use Databricks Langchain Chat Model wrapper to easily build our chain.  \n",
    "\n",
    "Note: multiple type of endpoint or langchain models can be used.\n",
    "\n",
    "- Databricks Foundation models (what we'll use)\n",
    "- Your fined-tune model\n",
    "- An external model provider (such as Azure OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae835cc1-7039-4c60-90ea-7116cc755584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks_langchain import ChatDatabricks\n",
    "\n",
    "# test Databricks Foundation LLM model\n",
    "chat_model = ChatDatabricks(endpoint=\"databricks-meta-llama-3-3-70b-instruct\", max_tokens = 300)\n",
    "print(f\"Test chat model: {chat_model.invoke('What is Generative AI?')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c0ca101-46b7-4672-bc6e-8c44be18594d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Assembling the Complete RAG Solution\n",
    "\n",
    "Let's now merge the retriever and the model in a single Langchain chain.\n",
    "\n",
    "We will use a custom langchain template for our assistant to give proper answer.\n",
    "\n",
    "Make sure you take some time to try different templates and adjust your assistant tone and personality for your requirement.\n",
    "\n",
    "<!-- <img src=\"https://files.training.databricks.com/images/genai/genai-as-01-llm-rag-self-managed-model-2.png\" width=\"100%\" /> -->\n",
    "\n",
    "![genai-as-01-llm-rag-self-managed-model-2](../Includes/images/genai-as-01-llm-rag-self-managed-model-2.png)\n",
    "\n",
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4586d49e-7a57-4a7b-b142-431f243acc6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Some important notes about the LangChain formatting:\n",
    "\n",
    "* Context documents retrieved from the vector store are added by separated newline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e74460ad-ddd8-40de-9e46-e5ad924802e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt template\n",
    "TEMPLATE = \"\"\"You are an assistant for GENAI teaching class. You are answering questions related to Generative AI and how it impacts humans life. If the question is not related to one of these topics, kindly decline to answer. \n",
    "Use the following pieces of context to answer the question at the end:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(TEMPLATE)      \n",
    "\n",
    "# Helper functions\n",
    "def format_docs(docs):\n",
    "    # what the model sees in {context}\n",
    "    return \"\\n\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "def unwrap(payload):\n",
    "    # return both answer and normalized context (dicts) like you wanted\n",
    "    docs = payload[\"docs\"]\n",
    "    return {\n",
    "        \"answer\": payload[\"answer\"],\n",
    "        \"context\": [{\"metadata\": getattr(d, \"metadata\", {}), \"page_content\": getattr(d, \"page_content\", \"\")}\n",
    "                    for d in docs],\n",
    "    }\n",
    "\n",
    "# ---- build the chain ----\n",
    "# Step 1: retrieve docs\n",
    "retrieve = RunnableParallel(input=RunnablePassthrough(), docs=get_retriever())\n",
    "\n",
    "# Step 2: pass formatted context + input to the model\n",
    "rag = retrieve | {\n",
    "    \"input\": itemgetter(\"input\"),\n",
    "    \"context\": RunnableLambda(lambda x: format_docs(x[\"docs\"]))\n",
    "} | prompt | chat_model | StrOutputParser()\n",
    "\n",
    "# Keep docs for postprocessing\n",
    "chain = retrieve | {\n",
    "    \"answer\": ({\"input\": itemgetter(\"input\"), \"context\": RunnableLambda(lambda x: format_docs(x[\"docs\"]))}\n",
    "               | prompt | chat_model | StrOutputParser()),\n",
    "    \"docs\": itemgetter(\"docs\"),\n",
    "} | RunnableLambda(unwrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a3fbf37-6251-4098-8791-e40fff87e95e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "question = {\"input\": \"What are the generative AI's economical implications?\"}\n",
    "response = chain.invoke(question)\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0574621-c0a1-45ee-9e5c-e93c7d59ed2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Save the Model to Model Registry in UC\n",
    "\n",
    "Now that our model is ready and evaluated, we can register it within our Unity Catalog schema. \n",
    "\n",
    "After registering the model, you can view the model and models in the **Catalog Explorer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7665648-d482-4ffd-aedc-b2824ff4a3ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature\n",
    "import mlflow\n",
    "import langchain\n",
    "\n",
    "# set model registry to UC\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "model_name = f\"{DA.catalog_name}.{DA.schema_name}.rag_app_demo4\"\n",
    "\n",
    "with mlflow.start_run(run_name=\"rag_app_demo4\") as run:\n",
    "    signature = infer_signature(question, response)\n",
    "    model_info = mlflow.langchain.log_model(\n",
    "        chain,\n",
    "        loader_fn=get_retriever, \n",
    "        name=\"chain\",\n",
    "        registered_model_name=model_name,\n",
    "        pip_requirements=[\n",
    "            \"mlflow==\" + mlflow.__version__,\n",
    "            \"langchain==\" + langchain.__version__,\n",
    "            \"databricks-vectorsearch\",\n",
    "        ],\n",
    "        signature=signature,\n",
    "        input_example=question\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de470a61-0176-4faa-afe3-00fb865300e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Clean up Resources\n",
    "\n",
    "This is the final demo. You can delete all resources created in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87921578-e7b3-4d1a-b32a-7d7f02e94e9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "In this demo, we illustrated the process of constructing a comprehensive RAG application utilizing a variety of Databricks products. Initially, we established the RAG components that were previously created in the earlier demos, namely the Vector Search endpoint and Vector Search index. Subsequently, we constructed the retriever component and set up the foundational model for use. Following this, we put together the entire RAG application and evaluated the performance of the pipeline using MLflow's LLM evaluation functions. As a final step, we registered the newly created RAG application as a model within the Model Registry with Unity Catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "437debc9-eefa-43d4-ba6e-3724211aad75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "4.1 - Assembling and Registering a RAG Application",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}