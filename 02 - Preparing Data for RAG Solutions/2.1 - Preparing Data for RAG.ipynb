{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5085e60b-5115-4193-899d-0837fa593859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e497b6e-89d1-4413-81f9-d54aa4f003ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Preparing Data for RAG\n",
    "\n",
    "\n",
    "**In this demo, we will focus on ingesting PDF documents as a source for our retrieval process.** First, we will ingest the PDF files and process them using self-managed vector search embeddings. \n",
    "\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "*By the end of this demo, you will be able to:*\n",
    "\n",
    "* Split the data into chunks that are at least as small as the maximum context window of the LLM to be used later.\n",
    "\n",
    "* Describe how to appropriately choose an embedding model.\n",
    "\n",
    "* Compute embeddings for each of the chunks using a Databricks-managed embedding model.\n",
    "\n",
    "* Use the chunking strategy to divide up the context information to be provided to a model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a7f3102-2880-44d4-b544-d87094dbf373",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "2. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "   - Click **More** in the drop-down.\n",
    "   \n",
    "   - In the **Attach to an existing compute resource** window, use the first drop-down to select your unique cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "2. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "3. Wait a few minutes for the cluster to start.\n",
    "\n",
    "4. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8c59605-c4a6-4ea9-9331-b4da172c52ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **17.3.x-cpu-ml-scala2.13**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79b01e25-0d3e-4fbe-a427-ca2b31b6961b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Classroom Setup\n",
    "\n",
    "Install required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60785b2f-bc04-48d3-83b1-9097add98fbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -qqqq -U mlflow==3.4.0 llama-index==0.14.5 PyPDF2==3.0.0\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "542f8166-b698-4e7b-a443-bd5623c14348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Before starting the demo, run the provided classroom setup script. This script will define the configuration variables necessary for the demo. Execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b74b22df-5e6d-4912-a9ec-d44330e3b998",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2066d52-2073-46f8-be1a-961b620d0a42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Other Conventions:**\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9940c71-8347-4fe8-8944-10f599d72e09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"Dataset Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b806c8d-4461-44a2-9503-49d7f64b34cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Demo Overview\n",
    "\n",
    "For this example, we will add research articles on GenerativeAI as PDFs from [Arxiv resources page](https://arxiv.org/abs/2309.07930) to our knowledge database.\n",
    "\n",
    "<!-- <img src=\"https://files.training.databricks.com/images/genai/genai-as-01-rag-pdf-self-managed-0.png\" style=\"float: right; width: 600px; margin-left: 10px\"> -->\n",
    "<!-- \n",
    " -->\n",
    "\n",
    "![genai-as-01-rag-pdf-self-managed-0](../Includes/images/genai-as-01-rag-pdf-self-managed-0.png)\n",
    "\n",
    "Here are all the detailed steps:\n",
    "\n",
    "- Use Spark to load the binary PDFs into our first table. \n",
    "- Use the `unstructured` library  to parse the text content of the PDFs.\n",
    "- Use `llama_index` or `langchain` to split the texts into chunks.\n",
    "- Compute embeddings for the chunks.\n",
    "- Save our text chunks + embeddings in a Delta Lake table, ready for Vector Search indexing.\n",
    "\n",
    "\n",
    "Databricks Lakehouse AI not only provides state of the art solutions to accelerate your AI and LLM projects but also to accelerate data ingestion and preparation at scale, including unstructured data like PDFs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7511f465-51ed-4ebc-8afd-06daf4e6e4f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Extract PDF Content as Text Chunks\n",
    "\n",
    "As the first step, we need to ingest PDF files and divide the content into chunks. PDF files are already downloaded during the course step and stored in **datasets path**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e792313-c721-47cf-8f7c-f94a7d4d2399",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reduce the arrow batch size as our PDF can be big in memory\n",
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90ef9384-4a45-445e-8209-4e3367ae11f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "articles_path = f\"{DA.paths.datasets.arxiv}/arxiv-articles/\"\n",
    "table_name = f\"{DA.catalog_name}.{DA.schema_name}.pdf_raw_text\"\n",
    "\n",
    "# read pdf files\n",
    "df = (\n",
    "        spark.read.format(\"binaryfile\")\n",
    "        .option(\"recursiveFileLookup\", \"true\")\n",
    "        .load(articles_path)\n",
    "        )\n",
    "\n",
    "# save list of the files to table\n",
    "df.write.mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17d6802d-c55a-443b-a3c9-423e5129e79e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's view the content of one of the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ce258b5-a1b6-4d12-8f21-6220e331d648",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The parse_bytes_pypdf function was created during our classroom setup using the PyPDF2 library. This function extracts text from a PDF file given its binary content.\n",
    "\n",
    "with open(f\"{articles_path}2302.06476.pdf\", mode=\"rb\") as pdf:\n",
    "  doc = parse_bytes_pypdf(pdf.read()) \n",
    "  print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "130a62b1-f5d2-4943-8f15-0cea761776d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This looks great. We'll now wrap it with a `text_splitter` to avoid having too big pages and create a **Pandas UDF function** to easily scale that across multiple nodes.\n",
    "\n",
    "**\uD83D\uDCCCNote:** The pdf text isn't clean. To make it nicer, we could use a few extra LLM-based pre-processing steps, asking to remove irrelevant content like the list of chapters and to only keep the core text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d882e49-03d9-4697-bdaf-2cadde727005",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.core.utils import set_global_tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Iterator\n",
    "from pyspark.sql.functions import col, udf, length, pandas_udf, explode\n",
    "from PyPDF2 import PdfReader  # Updated import\n",
    "\n",
    "# Define a function to split the text content into chunks\n",
    "@pandas_udf(\"array<string>\")\n",
    "def read_as_chunk(batch_iter: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    # Set llama2 as tokenizer\n",
    "    set_global_tokenizer(\n",
    "      AutoTokenizer.from_pretrained(\"hf-internal-testing/llama-tokenizer\")\n",
    "    )\n",
    "    # Sentence splitter from llama_index to split on sentences\n",
    "    splitter = SentenceSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    \n",
    "    def extract_and_split(b):\n",
    "        txt = parse_bytes_pypdf(b)  # Use custom function\n",
    "        if txt is None:\n",
    "            return []\n",
    "        nodes = splitter.get_nodes_from_documents([Document(text=txt)])\n",
    "        return [n.text for n in nodes]\n",
    "\n",
    "    for x in batch_iter:\n",
    "        yield x.apply(extract_and_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f26e1c3b-8f70-43fc-9b4f-5277877c0ff8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_chunks = (df\n",
    "                .withColumn(\"content\", explode(read_as_chunk(\"content\")))\n",
    "                .selectExpr('path as pdf_name', 'content')\n",
    "                )\n",
    "display(df_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fcff172-9db4-448d-8378-c967d9d4da83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**\uD83D\uDCA1 Chunking Overlap**: Review the content chunks and pay attention to the sentence overlap between chunks. This was defined with `SentenceSplitter` above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90cab243-393f-4902-97b5-4f54600e9b42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Embeddings with Foundation Model Endpoints\n",
    "\n",
    "<!-- <img src=\"https://files.training.databricks.com/images/genai/genai-as-01-rag-pdf-self-managed-4.png\" width=\"100%\"> -->\n",
    "\n",
    "<!--  -->\n",
    "\n",
    "![genai-as-01-rag-pdf-self-managed-4](../Includes/images/genai-as-01-rag-pdf-self-managed-4.png)\n",
    "\n",
    "Foundation Models are provided by Databricks, and can be used out-of-the-box.\n",
    "\n",
    "Databricks supports several endpoint types to compute embeddings or evaluate a model:\n",
    "- A **foundation model endpoint**, provided by databricks (ex: llama3.3-70B, databricks-claude-3-7-sonnet...)\n",
    "- An **external endpoint**, acting as a gateway to an external model (ex: Azure OpenAI)\n",
    "- A **custom**, fine-tuned model hosted on Databricks model service\n",
    "\n",
    "Open the [Model Serving Endpoint page](/ml/endpoints) to explore and try the foundation models.\n",
    "\n",
    "For this demo, we will use the foundation model `GTE` (embeddings) and `llama3.3-70B` (chat). <br/><br/>\n",
    "\n",
    "<!--  -->\n",
    "\n",
    "![serving](../Includes/images/serving.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15f4e88b-6e7b-4068-bff4-8a96f2cc87dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### How to Use Foundation Model API\n",
    "\n",
    "Before computing the embeddings for the chunked text we created before, let's quickly go over how to use Foundation Model API.\n",
    "\n",
    "**\uD83D\uDEA8 Important:** You will need Foundation Model API access for this section and the rest of the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c01573e3-f636-45ad-b29f-a0486cc9412c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "\n",
    "# gte-large-en Foundation models are available using the /serving-endpoints/databricks-gte-large-en/invocations api. \n",
    "deploy_client = get_deploy_client(\"databricks\")\n",
    "\n",
    "# NOTE: if you change your embedding model here, make sure you change it in the query step too\n",
    "embeddings = deploy_client.predict(endpoint=\"databricks-gte-large-en\", inputs={\"input\": [\"What is Apache Spark?\"]})\n",
    "pprint(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86144c6b-9c60-49db-bbe1-f7f1dc7f350e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Compute Chunking Embeddings\n",
    "\n",
    "The last step is to now compute an embedding for all our documentation chunks. Let's create an udf to compute the embeddings using the foundation model endpoint.\n",
    "\n",
    "**\uD83D\uDCCC Note:** This part would typically be setup as a production-grade job, running as soon as a new documentation page is updated.\n",
    "This could be setup as a Delta Live Table pipeline to incrementally consume updates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "119e3453-b145-4bea-9b81-44ade5d65580",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@pandas_udf(\"array<float>\")\n",
    "def get_embedding(contents: pd.Series) -> pd.Series:\n",
    "    import mlflow.deployments\n",
    "    deploy_client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "    def get_embeddings(batch):\n",
    "        # NOTE: this will fail if an exception is thrown during embedding creation (add try/except if needed) \n",
    "        response = deploy_client.predict(endpoint=\"databricks-gte-large-en\", inputs={\"input\": batch})\n",
    "        return [e[\"embedding\"] for e in response.data]\n",
    "\n",
    "    # splitting the contents into batches of 150 items each, since the embedding model takes at most 150 inputs per request.\n",
    "    max_batch_size = 150\n",
    "    batches = [contents.iloc[i:i + max_batch_size] for i in range(0, len(contents), max_batch_size)]\n",
    "\n",
    "    # process each batch and collect the results\n",
    "    all_embeddings = []\n",
    "    for batch in batches:\n",
    "        all_embeddings += get_embeddings(batch.tolist())\n",
    "\n",
    "    return pd.Series(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71ac18e3-04c3-45e5-9888-a675d4e74dae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df_chunk_emd = (df_chunks\n",
    "                .withColumn(\"embedding\", get_embedding(\"content\"))\n",
    "                .selectExpr(\"pdf_name\", \"content\", \"embedding\")\n",
    "                )\n",
    "display(df_chunk_emd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b14eef7-6738-41c5-8d82-bd16e7fd652b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Save Embeddings to a Delta Table\n",
    "\n",
    "Now that the embeddings are ready, let's create a Delta table and store the embeddings in this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37ffa822-c03b-43bd-984e-ee4d42db26b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS pdf_text_embeddings (\n",
    "  id BIGINT GENERATED BY DEFAULT AS IDENTITY,\n",
    "  pdf_name STRING,\n",
    "  content STRING,\n",
    "  embedding ARRAY <FLOAT>\n",
    "  -- NOTE: the table has to be CDC because VectorSearch is using DLT that is requiring CDC state\n",
    "  ) TBLPROPERTIES (delta.enableChangeDataFeed = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69bbd496-99ff-4461-82b3-51278a94c0c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "embedding_table_name = f\"{DA.catalog_name}.{DA.schema_name}.pdf_text_embeddings\"\n",
    "df_chunk_emd.write.mode(\"append\").saveAsTable(embedding_table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bd3e32a-7881-4a51-b5bf-5160af87f6cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Clean up Classroom\n",
    "\n",
    "**\uD83D\uDEA8 Warning:** Please refrain from deleting the tables created in this demo, as they are required for upcoming demos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a5e5893-cfa3-471a-99a8-85903389252d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "In this demo, we demonstrated how to ingest and process documents for a RAG application. The first step was to extract text chunks from PDF documents. Then, we created embeddings using a foundation model. This process includes setting up an endpoint and computing embeddings for the chunks. In the final step, we stored computed embeddings in a Delta table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a53f195-05b4-4b40-a5d1-b273d7a4bde2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2.1 - Preparing Data for RAG",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}